{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "hw2_nlp.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT6FDbl2bXSn"
      },
      "source": [
        "from natasha import (\n",
        "    Segmenter,\n",
        "    MorphVocab,\n",
        "    NewsEmbedding,\n",
        "    NewsMorphTagger,\n",
        "    Doc\n",
        ")\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pymystem3 import Mystem\n",
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "import spacy\n",
        "\n",
        "morph = MorphAnalyzer()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t05AxKRAeRbX"
      },
      "source": [
        "## Русский"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEZ0Jbk9eXSG"
      },
      "source": [
        "Некоторые модули не работали в колабе, а другие локально, поэтому код совмещенный (но он честно работает). Для русского взяла текст с кучей омографов(разных слов, которые пишутся одинаково), т.к однозначно различить их по тексту можно только зная окружающий контекст."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv9DmvgZbXSy"
      },
      "source": [
        "with open('rus_text.txt',encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "words = [w.lower() for w in word_tokenize(text) if w.isalpha()]\n",
        "doc = Doc(' '.join(words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNnDdQdwbXS2",
        "outputId": "763e5aee-5b9c-494c-95eb-8d0b032ab0a1"
      },
      "source": [
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Пойдем, сходим к берегу. Я берегу деньги на черный день. Нам любые дороги дороги. Солнце село, стало темно, собралось всё село. Внизу огромная пропасть, не хотелось бы в нее попасть и пропасть. Печь пирожки в печи. Видны голубые дали. Ему дали совет. Время и стекло. Вода стекла на пол. Мой яблоко. Иванов пил сок. Никто не нашёл острых пил. Ветер стих. Сорок стихов. Сейчас – начало осени. Начало смеркаться. Ели растут в лесу. Мы ели сыр и выпили много вина. Это не твоя вина, что воздух сыр. Мы видим солнце, море и чаек над водой. Совсем уже не видим месяц за облаками.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTTUsj_ZbXS6"
      },
      "source": [
        "### Наташа"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7AfzzkRbXS7"
      },
      "source": [
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)\n",
        "segmenter = Segmenter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbkEllBLbXS-"
      },
      "source": [
        "doc.segment(segmenter)\n",
        "doc.tag_morph(morph_tagger)\n",
        "nat_pos_list = []\n",
        "for token in doc.tokens:\n",
        "    nat_pos_list.append(token.pos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvim3itIbXTJ"
      },
      "source": [
        "### Mystem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR7ISlDSbXTK",
        "outputId": "32aa8561-67c1-4a43-a3fb-f4ae95c52139"
      },
      "source": [
        "#mystem работает в тысячу раз быстрее через консоль\n",
        "inp = 'rus_text.txt'\n",
        "outp = \"rus_text.json\"\n",
        "mystem_path = os.path.join('/Users/User', 'mystem.exe')\n",
        "\n",
        "input_filename = os.path.abspath(inp)\n",
        "output_filename = os.path.abspath(outp)\n",
        "os.system(f\"{mystem_path} {'-gin'} {'--format json'} {input_filename} {output_filename}\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCLBmU0obXTM"
      },
      "source": [
        "ana_list = []\n",
        "myst_pos_list = []\n",
        "with open('rus_text.json', encoding='utf-8') as f:\n",
        "    text2 = f.read()\n",
        "    lines = text2.splitlines()\n",
        "\n",
        "for line in lines:\n",
        "    data = json.loads(line)['analysis']\n",
        "    ana_list.append(data)\n",
        "    \n",
        "for i in range(len(ana_list)):\n",
        "    if ana_list[i] == []:\n",
        "        pos = 'UNK'\n",
        "    else:\n",
        "        pos = re.match('.+?(?=[,=])',ana_list[i][0]['gr']).group()\n",
        "    myst_pos_list.append(pos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iR1GSSlbXTQ"
      },
      "source": [
        "### Pymorphy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Zmrvjs_bXTS"
      },
      "source": [
        "pym_pos_list = []\n",
        "\n",
        "for word in words:\n",
        "    ana = morph.parse(word)\n",
        "    first = ana[0] # использую только 1-й вариант разбора\n",
        "    pos = first.tag.POS  \n",
        "    pym_pos_list.append(str(pos))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnye8ldzbXTV"
      },
      "source": [
        "### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjxYBaOgbXTV"
      },
      "source": [
        "#текст с моей ручной разметкой\n",
        "with open('gold.txt',encoding='utf-8') as f:\n",
        "    gold = f.read()\n",
        "    gold = gold.split('\\n') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZI2wMctbXTX"
      },
      "source": [
        "def convert(pos_list):\n",
        "    conv_pos_list = []\n",
        "    for tag in pos_list:\n",
        "        if tag in ['A','ADJ','ADJF','ADJS','JJ','JJR','JJS']:\n",
        "            new_tag = 'ADJ'\n",
        "        elif tag in ['S','NOUN','NN','NNS']:\n",
        "            new_tag = 'NOUN'\n",
        "        elif tag in ['V','VERB','INFN','VBG','MD','VB','VBD','VBN','VBP','VBZ']:\n",
        "            new_tag = 'VERB'\n",
        "        elif tag in ['NPRO','PRON','PRP']:\n",
        "            new_tag = 'PRON'\n",
        "        elif tag in ['CONJ','CCONJ','SCONJ','CC']:\n",
        "            new_tag = 'CONJ'\n",
        "        elif tag in ['PREP','ADP','PR','IN','RP']:\n",
        "            new_tag = 'ADP'\n",
        "        elif tag in ['ADV','ADVB','RB','RBR']:\n",
        "            new_tag = 'ADV'\n",
        "        elif tag in ['PART','PRCL','POS','TO']:\n",
        "            new_tag = 'PART'\n",
        "        elif tag in ['PROPN','NNP','NNPS']:\n",
        "            new_tag = 'PROPN'\n",
        "        elif tag in ['NUM','NUMR','CD']:\n",
        "            new_tag = 'NUM'\n",
        "        elif tag in ['AUX']:\n",
        "            new_tag = 'AUX'\n",
        "        elif tag in ['DET','DT','PDT','PRP$']:\n",
        "            new_tag = 'DET'\n",
        "        \n",
        "        else:\n",
        "            new_tag = 'OTHER'\n",
        "        conv_pos_list.append(new_tag) \n",
        "    return conv_pos_list"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2qeDb6HVbXTb",
        "outputId": "6726f0db-5a4d-45a2-e56b-268032f9dd96"
      },
      "source": [
        "print('Mystem',\"Accuracy: %.4f\" % accuracy_score(convert(myst_pos_list), gold))\n",
        "print('Pymorphy',\"Accuracy: %.4f\" % accuracy_score(convert(pym_pos_list), gold))\n",
        "print('Natasha',\"Accuracy: %.4f\" % accuracy_score(convert(nat_pos_list), gold))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mystem Accuracy: 0.7327\n",
            "Pymorphy Accuracy: 0.8020\n",
            "Natasha Accuracy: 0.7822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMSQc_FUbXTd"
      },
      "source": [
        "## Английский "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeyJLimIeD7R"
      },
      "source": [
        "С английским тоже взяла текст с кучей омографов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMdxe9mubXTd"
      },
      "source": [
        "with open('homographes.txt',encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "words = [w.lower() for w in word_tokenize(text) if w.isalpha()]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdG6q3c2bXTf",
        "outputId": "e2f8f35a-84f8-4f5f-82ab-c08d17375a5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "text"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Gold is heavier than lead. They are going to mass this morning. The tiger was now so close that I could smell it... I will be there in a minute. That is a very minute amount. Wind your watch. The wind howled through the woodlands. The mass is sufficient for nuclear fission. The mother duck will lead her ducklings around. \"Will you close that door!\" In the word ‘dinner’ the accent is on the first syllable. Andy was a good husband, and Nicky was clearly very content. We all have different learned responses to anger. The plane left for Dallas last night. Look left and right before you cross the road.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7Trr3PfbXTh"
      },
      "source": [
        "### NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpdV_PuybXTh"
      },
      "source": [
        "nltk_pos_list = []\n",
        "tagged = nltk.pos_tag(words)\n",
        "for word in tagged:\n",
        "    pos = word[1]\n",
        "    nltk_pos_list.append(pos)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqwq2zSKbXTj"
      },
      "source": [
        "### Flair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsAh295tbXTl",
        "outputId": "9fbdbbaa-83d2-48a1-fdc8-4d632d98b2f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "tagger = SequenceTagger.load('upos')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 20:42:25,106 https://nlp.informatik.hu-berlin.de/resources/models/upos/en-pos-ontonotes-v0.4.pt not found in cache, downloading to /tmp/tmp25_aexok\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 432218302/432218302 [00:19<00:00, 22682550.62B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 20:42:44,661 copying /tmp/tmp25_aexok to cache at /root/.flair/models/en-pos-ontonotes-v0.4.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-18 20:42:45,868 removing temp file /tmp/tmp25_aexok\n",
            "2020-10-18 20:42:45,919 loading file /root/.flair/models/en-pos-ontonotes-v0.4.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQRY6w80bXTn"
      },
      "source": [
        "flair_pos_list = []\n",
        "for word in words:\n",
        "    sentence = Sentence(word)\n",
        "    tagger.predict(sentence)\n",
        "    ana = sentence.to_tagged_string()\n",
        "    pos = ana.split()[1]\n",
        "    pos = re.sub('[<>]','', pos)\n",
        "    flair_pos_list.append(pos)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSnryStlbXTo"
      },
      "source": [
        "### Spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGTqCvRLbXTp"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcRKmIJCbXTr"
      },
      "source": [
        "spacy_pos_list = []\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "for word in doc:\n",
        "    if word.pos_ != 'PUNCT':\n",
        "        spacy_pos_list.append(word.pos_)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buIIBLnHbXTt"
      },
      "source": [
        "### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-JzY8KBbXTu"
      },
      "source": [
        "#текст с моей ручной разметкой\n",
        "with open('eng_gold.txt',encoding='utf-8') as f:\n",
        "    eng_gold = f.read()\n",
        "    eng_gold = eng_gold.split('\\n')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqqdzLChbXTw",
        "outputId": "62eeac34-efee-4ddb-a345-2de7793d5f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print('NLTK',\"Accuracy: %.4f\" % accuracy_score(convert(nltk_pos_list), eng_gold))\n",
        "print('Flair',\"Accuracy: %.4f\" % accuracy_score(convert(flair_pos_list), eng_gold))\n",
        "print('Spacy',\"Accuracy: %.4f\" % accuracy_score(convert(spacy_pos_list), eng_gold))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Accuracy: 0.7838\n",
            "Flair Accuracy: 0.6577\n",
            "Spacy Accuracy: 0.9640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYwkaYbkdwVF"
      },
      "source": [
        "Spacy получился самым эффективным (по крайней мере, на этом тексте)"
      ]
    }
  ]
}
